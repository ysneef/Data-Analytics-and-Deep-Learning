{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDE877j4bENVDUMdWivEKk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysneef/Data-Analytics-and-Deep-Learning/blob/main/2174802010854-VoHuynhNhuY-Lab07/lab7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LAB 7:\n",
        "# PHÂN TÍCH DỮ LIỆU DẠNG VĂN BẢN VỚI NLTK"
      ],
      "metadata": {
        "id": "0yGNMzt1n-xY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**1. Giới thiệu về thư viện NLTK:**\n",
        "\n"
      ],
      "metadata": {
        "id": "_F1L8n0ToD8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import thư viện NLTK và download công cụng NLTK"
      ],
      "metadata": {
        "id": "BwukG2qboKPf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ2gXTgImzN8",
        "outputId": "f9c25219-cfc9-4436-edba-bf8fee644b03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> gutenberg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading package gutenberg to /root/nltk_data...\n",
            "      Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download_shell()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đối với những lần sau, nếu bạn đã biết tên của gói bạn muốn tải xuống, chỉ cần nhập lệnh\n",
        "nltk.download() với tên gói là tham số đầu vào. Thao tác này sẽ không mở công cụ NLTK\n",
        "Downloader, nhưng sẽ trực tiếp tải xuống gói yêu cầu. Vì vậy, thao tác trước đó tương đương với\n",
        "việc viết lệnh sau:"
      ],
      "metadata": {
        "id": "O8zgs5-LrJKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('gutenberg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGyVPiGfrJ4J",
        "outputId": "50aa2379-8f5b-41d1-a65f-e6c92496bb2c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpLbXTTnnjd6",
        "outputId": "b7e64a74-a940-4b7c-e912-08349008e16d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sau khi hoàn tất, bạn có xem tên các tập tin có trong gói 'gutenberg' bằng lệnh fileids()"
      ],
      "metadata": {
        "id": "8_Xb-hXCrEN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gb = nltk.corpus.gutenberg\n",
        "print(\"Gutenberg files : \", gb.fileids())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6TJiV48naOo",
        "outputId": "381fe38c-8da3-405a-f475-0e1db3a776cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gutenberg files :  ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Để truy cập nội dung bên trong của một trong các tập tin này, trước tiên bạn chọn một tập tin,\n",
        "chẳng hạn Macbeth của Shakespeare (shakespeare-macbeth.txt), sử dụng hàm words (), rồi gán\n",
        "cho một biến nào đó."
      ],
      "metadata": {
        "id": "Ld-Aw8ANrY2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "macbeth = nltk.corpus.gutenberg.words('shakespeare-macbeth.txt')"
      ],
      "metadata": {
        "id": "Jz7z97h6nfgi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nếu bạn muốn biết chiều dài của văn bản trên (bao nhiêu từ), bạn dùng hàm len()\n"
      ],
      "metadata": {
        "id": "XMlTIErgrbfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(macbeth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDqi-UXinzp5",
        "outputId": "e3fabc83-55fb-4a76-bdba-b01870840b4d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23140"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nếu bạn muốn hiển thị 10 từ đầu tiên của tập tin\n"
      ],
      "metadata": {
        "id": "KU-B332Xrdkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "macbeth [:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyaIUVkRn2oL",
        "outputId": "04d1b49e-d71d-4e20-e426-c5a3459fc69b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[',\n",
              " 'The',\n",
              " 'Tragedie',\n",
              " 'of',\n",
              " 'Macbeth',\n",
              " 'by',\n",
              " 'William',\n",
              " 'Shakespeare',\n",
              " '1603',\n",
              " ']']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta muốn trích 5 câu đầu tiên của tập tin (một câu được kẹp trong cặp ngoặc vuông), ta dùng hàm\n",
        "sent()\n"
      ],
      "metadata": {
        "id": "lw8bv_fPrnmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "macbeth_sents = nltk.corpus.gutenberg.sents('shakespeare-macbeth.txt')\n",
        "macbeth_sents[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3ir18qmn4pW",
        "outputId": "c0329d4e-7b1c-4944-d6ba-0199789ceee7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['[',\n",
              "  'The',\n",
              "  'Tragedie',\n",
              "  'of',\n",
              "  'Macbeth',\n",
              "  'by',\n",
              "  'William',\n",
              "  'Shakespeare',\n",
              "  '1603',\n",
              "  ']'],\n",
              " ['Actus', 'Primus', '.'],\n",
              " ['Scoena', 'Prima', '.'],\n",
              " ['Thunder', 'and', 'Lightning', '.'],\n",
              " ['Enter', 'three', 'Witches', '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Tìm 1 từ với NLTK:**"
      ],
      "metadata": {
        "id": "jMfBsuSmohQD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tìm từ ‘Stage’ xuất hiện trong văn bản text"
      ],
      "metadata": {
        "id": "XgdB_yuIojn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = nltk.Text(macbeth)\n",
        "text.concordance('Stage')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVErHIsEohpb",
        "outputId": "1a5f8ffa-b562-4bf5-ee07-ee816c9fe46d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 3 of 3 matches:\n",
            "nts with Dishes and Seruice ouer the Stage . Then enter Macbeth Macb . If it we\n",
            "with mans Act , Threatens his bloody Stage : byth ' Clock ' tis Day , And yet d\n",
            " struts and frets his houre vpon the Stage , And then is heard no more . It is \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tìm từ xuất hiện trước và sau từ ‘Stage’"
      ],
      "metadata": {
        "id": "VH9NDiahoo0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text.common_contexts(['Stage'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-32zS5Iaop3y",
        "outputId": "e9cdd8f2-436b-4044-929f-b94f50057277"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the_. bloody_: the_,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tìm từ tương tự từ ‘Stage’"
      ],
      "metadata": {
        "id": "X7JN1GZkor-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text.similar('Stage')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x86u-QU9otMV",
        "outputId": "8be5f65b-a287-4780-c7c4-0cca6937cd60"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day time face warre ayre king bleeding man reuolt serieant like\n",
            "knowledge broyle shew head spring heeles hare thane skie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Phân tích tần số của các từ**"
      ],
      "metadata": {
        "id": "LIHo_YRfo9Ya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Muốn xem 10 từ thông dụng nhất trong văn bản xuất hiện bao nhiêu lần, dùng lệnh\n",
        "most_common()"
      ],
      "metadata": {
        "id": "JXhdGVjopBFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fd = nltk.FreqDist(macbeth)\n",
        "fd.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P6_wu-7o-QS",
        "outputId": "01723bcf-fa55-4c86-ed80-0b53b58c783e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 1962),\n",
              " ('.', 1235),\n",
              " (\"'\", 637),\n",
              " ('the', 531),\n",
              " (':', 477),\n",
              " ('and', 376),\n",
              " ('I', 333),\n",
              " ('of', 315),\n",
              " ('to', 311),\n",
              " ('?', 241)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Muốn download stopword"
      ],
      "metadata": {
        "id": "hLFY83sdpGQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piUasb84pGrp",
        "outputId": "03eaa21b-db99-416b-cc10-b65dabd4d80e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Muốn xem các stopword trong tiếng Anh, dùng lệnh"
      ],
      "metadata": {
        "id": "uDKahQvNpJXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sw = set(nltk.corpus.stopwords.words('english'))\n",
        "print(len(sw))\n",
        "list(sw)[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkFnWYewpKID",
        "outputId": "a18410d2-8933-4d4f-c2c4-6011fbd4092e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "198\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"she's\",\n",
              " 'once',\n",
              " \"you're\",\n",
              " 'a',\n",
              " \"needn't\",\n",
              " 'against',\n",
              " 'with',\n",
              " 'who',\n",
              " 'as',\n",
              " 'shouldn']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Có 179 stopword trong từ vựng tiếng Anh. Ta sẽ loại bỏ các từ stopword trong biến macbeth"
      ],
      "metadata": {
        "id": "EXImCHQqpL6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "macbeth_filtered = [w for w in macbeth if w.lower() not in sw]\n",
        "len(macbeth_filtered)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgl4u_TBpNoh",
        "outputId": "03c1602a-2d88-4d1b-9134-54ff6df22367"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14946"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd = nltk.FreqDist(macbeth_filtered)\n",
        "fd.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdq-wLxZpTLI",
        "outputId": "eef9ee25-6ae7-4794-9315-90f42881749b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 1962),\n",
              " ('.', 1235),\n",
              " (\"'\", 637),\n",
              " (':', 477),\n",
              " ('?', 241),\n",
              " ('Macb', 137),\n",
              " ('haue', 117),\n",
              " ('-', 100),\n",
              " ('Enter', 80),\n",
              " ('thou', 63)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loại bỏ các dấu câu theo lệnh sau"
      ],
      "metadata": {
        "id": "9X3s0vYFpQQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "punctuation = set(string.punctuation)\n",
        "macbeth_filtered2 = [w.lower() for w in macbeth if w.lower() not in sw and w.lower() not in punctuation]\n",
        "fd = nltk.FreqDist(macbeth_filtered2)\n",
        "fd.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IggiyrpgpXjR",
        "outputId": "5183123e-2924-40a2-831f-2ea03f80aecb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('macb', 137),\n",
              " ('haue', 122),\n",
              " ('thou', 90),\n",
              " ('enter', 81),\n",
              " ('shall', 68),\n",
              " ('macbeth', 62),\n",
              " ('vpon', 62),\n",
              " ('thee', 61),\n",
              " ('macd', 58),\n",
              " ('vs', 57)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Lựa chọn các từ trong văn bản**"
      ],
      "metadata": {
        "id": "SlAMhU1Xpkkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rút trích các từ có độ dài lớn nhất, ví dụ các từ có độ dài lớn hơn 12 ký tự , dùng lệnh sau:"
      ],
      "metadata": {
        "id": "Vp81LgOTp9YB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "long_words = [w for w in macbeth if len(w)> 12]\n",
        "sorted(long_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNf4ucHOpk2G",
        "outputId": "c0d03cb3-8f75-4517-a6dd-fcbb188998b6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Assassination',\n",
              " 'Chamberlaines',\n",
              " 'Distinguishes',\n",
              " 'Gallowgrosses',\n",
              " 'Metaphysicall',\n",
              " 'Northumberland',\n",
              " 'Voluptuousnesse',\n",
              " 'commendations',\n",
              " 'multitudinous',\n",
              " 'supernaturall',\n",
              " 'vnaccompanied']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rút trích các từ có chứa chuỗi ‘ious’\n"
      ],
      "metadata": {
        "id": "VOxopLAqqAXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ious_words = [w for w in macbeth if 'ious' in w]\n",
        "ious_words = set(ious_words)\n",
        "sorted(ious_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySthhK-DqA3X",
        "outputId": "86fb39c5-143d-44ea-ab50-cc4191daa012"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Auaricious',\n",
              " 'Gracious',\n",
              " 'Industrious',\n",
              " 'Iudicious',\n",
              " 'Luxurious',\n",
              " 'Malicious',\n",
              " 'Obliuious',\n",
              " 'Pious',\n",
              " 'Rebellious',\n",
              " 'compunctious',\n",
              " 'furious',\n",
              " 'gracious',\n",
              " 'pernicious',\n",
              " 'pernitious',\n",
              " 'pious',\n",
              " 'precious',\n",
              " 'rebellious',\n",
              " 'sacrilegious',\n",
              " 'serious',\n",
              " 'spacious',\n",
              " 'tedious']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Bigrams và collocations**\n"
      ],
      "metadata": {
        "id": "BcrVDbylqCzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lọc các bigram sau khi đã loại các stopword và các dấu câu, dùng lệnh sau:"
      ],
      "metadata": {
        "id": "0gV7JzV7qGl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bgrms = nltk.FreqDist(nltk.bigrams(macbeth_filtered2))\n",
        "bgrms.most_common(15)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmE3AK-UqEZj",
        "outputId": "68b4f4fd-2da9-4c32-dea1-034283b8192f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('enter', 'macbeth'), 16),\n",
              " (('exeunt', 'scena'), 15),\n",
              " (('thane', 'cawdor'), 13),\n",
              " (('knock', 'knock'), 10),\n",
              " (('st', 'thou'), 9),\n",
              " (('thou', 'art'), 9),\n",
              " (('lord', 'macb'), 9),\n",
              " (('haue', 'done'), 8),\n",
              " (('macb', 'haue'), 8),\n",
              " (('good', 'lord'), 8),\n",
              " (('let', 'vs'), 7),\n",
              " (('enter', 'lady'), 7),\n",
              " (('wee', 'l'), 7),\n",
              " (('would', 'st'), 6),\n",
              " (('macbeth', 'macb'), 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ngoài bigram ra, còn có trigram, sự kết hợp của 3 từ, ta dùng lệnh trigrams()\n"
      ],
      "metadata": {
        "id": "ZjKpQx07qLI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tgrms = nltk.FreqDist(nltk.trigrams (macbeth_filtered2))\n",
        "tgrms.most_common(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSgcFCgrqLZJ",
        "outputId": "b97e1c01-4c7e-4311-97bb-bf9ef8edd5cf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('knock', 'knock', 'knock'), 6),\n",
              " (('enter', 'macbeth', 'macb'), 5),\n",
              " (('enter', 'three', 'witches'), 4),\n",
              " (('exeunt', 'scena', 'secunda'), 4),\n",
              " (('good', 'lord', 'macb'), 4),\n",
              " (('three', 'witches', '1'), 3),\n",
              " (('exeunt', 'scena', 'tertia'), 3),\n",
              " (('thunder', 'enter', 'three'), 3),\n",
              " (('exeunt', 'scena', 'quarta'), 3),\n",
              " (('scena', 'prima', 'enter'), 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Sử dụng văn bản trên mạng**"
      ],
      "metadata": {
        "id": "uQYDEQeBrzHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import thư viện và mở url để đọc file\n"
      ],
      "metadata": {
        "id": "lMs_skGwr8MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib import request\n",
        "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
        "response = request.urlopen(url)\n",
        "raw = response.read().decode('utf8')\n",
        "raw[:75]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QjdQYZX1r9Sm",
        "outputId": "c1ba7fae-d48d-4f6b-b80e-0c27be604443"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'*** START OF THE PROJECT GUTENBERG EBOOK 2554 ***\\n\\n\\n\\n\\nCRIME AND PUNISHMENT\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thay bằng các lệnh sau:\n"
      ],
      "metadata": {
        "id": "5l82yETXsCGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib import request\n",
        "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
        "response = request.urlopen(url)\n",
        "raw = response.read().decode('utf-8-sig')\n",
        "raw[:75]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "--k-Lpn5r1pp",
        "outputId": "489082b6-42bf-4528-b12f-8e1977d1f53f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'*** START OF THE PROJECT GUTENBERG EBOOK 2554 ***\\n\\n\\n\\n\\nCRIME AND PUNISHMENT\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thực hiện các lệnh sau:"
      ],
      "metadata": {
        "id": "bWQ24owRsMI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = nltk.word_tokenize (raw)\n",
        "webtext = nltk.Text (tokens)\n",
        "webtext[:12]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J7HzIT9sNqV",
        "outputId": "1656e10b-9e46-47bc-dfeb-2687a32061cf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['*',\n",
              " '*',\n",
              " '*',\n",
              " 'START',\n",
              " 'OF',\n",
              " 'THE',\n",
              " 'PROJECT',\n",
              " 'GUTENBERG',\n",
              " 'EBOOK',\n",
              " '2554',\n",
              " '*',\n",
              " '*']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Rút trích văn bản từ trang html**"
      ],
      "metadata": {
        "id": "JTBt_vJUsT5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "cách rút trích văn\n",
        "bản từ trang html."
      ],
      "metadata": {
        "id": "iof8DDZVse7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
        "html = request.urlopen(url).read().decode('utf8')\n",
        "html[:120]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zUlU7S0AsVsr",
        "outputId": "ffdb5139-f653-4169-f3b9-a75c3796f413"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/loose.dtd\">\\r\\n<html>\\r\\n<hea'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta dùng thư viện bs4 (BeautifulSoup) cung cấp cho bạn các trình phân tích cú pháp phù hợp có\n",
        "thể nhận dạng HTML và trích xuất văn bản."
      ],
      "metadata": {
        "id": "GmQch3Kisn9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "raw = BeautifulSoup(html, \"lxml\").get_text()\n",
        "tokens = nltk.word_tokenize(raw)\n",
        "text = nltk.Text(tokens)\n"
      ],
      "metadata": {
        "id": "YMv6JVyAsoXZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Phân tích cảm xúc người dùng**"
      ],
      "metadata": {
        "id": "Jlt-1aCnsqGJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "download các movie review dùng lệnh sau:"
      ],
      "metadata": {
        "id": "-LwMqNPasvzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('movie_reviews')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRlIwms1srz9",
        "outputId": "91e5a4f4-e0e7-4639-b371-bcbed7b8330e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sau đó xây dựng tập train dựa vào copus trên. Tạo 1 mảng tên là documents. Mảng này chứa cột\n",
        "đầu tiên là nội dung review của người dùng, và cột thứ 2 là cột đánh giá positive, neutral, or\n",
        "negative. Sau đó trộn các dòng này ngẫn nhiên"
      ],
      "metadata": {
        "id": "v7owb2ags2aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "reviews = nltk.corpus.movie_reviews\n",
        "documents = [(list(reviews.words(fileid)), category)\n",
        "for category in reviews.categories()\n",
        "for fileid in reviews.fileids(category)]\n",
        "random.shuffle(documents)\n"
      ],
      "metadata": {
        "id": "nJdksG28s290"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Xem nội dung review đầu tiên (dòng 0, cột 0)\n"
      ],
      "metadata": {
        "id": "KGbFxgI8s8d4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_review = ' '.join(documents[0][0])\n",
        "print(first_review)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeefUBKOs-Ah",
        "outputId": "dff6e8a1-1625-4008-a279-d2158661582c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "note : some may consider portions of the following text to be spoilers . be forewarned . milos forman ' s first film since the ill - fated valmont , columbia ' s the people vs . larry flynt , is a vastly entertaining ( if not particularly enlightening ) biopic of hustler publisher and self - made millionaire larry flynt , who became an unlikely champion of freedom of speech rights in the united states in the late 1970s and early 1980s . the film unweaves its tale in a chronological order : we open with young and dirt - poor larry flynt and his brother jimmy , peddling jars of water in true entrepreneurial spirit out in the rural outback of kentucky . cut to forward in time , where the two flynt brothers , now young men , are running the struggling hustler go - go clubs in cincinnati . the strip clubs are in a dire financial state , and in a last - ditch effort to salvage the operations , flynt decides to go to a print shop and churn out a promotional newsletter . this evolved into the adult periodical _hustler_ magazine , creating larry flynt a vast financial empire , and the rest is history . what sets flynt apart from other publishers is his struggles against those who would have him cease publication of his adult material , and who railed and preached against him - flynt spent time in incarceration and was paralyzed by an assassination attempt - and his driven , single - minded insistence to buck the system and fight for his freedom of expression , regardless of personal cost . the people vs . larry flynt also weaves in the bittersweet story of flynt ' s true love , althea leasure , whom he meets as a dancer in his club and later marries , and who devotedly stands alongside him throughout his trials and tribulations . considering the serious nature of the film ' s theme - the importance of the united states ' first amendment - the people vs . larry flynt is surprisingly and wonderfully light - hearted and humourous . much of the comedy is elicited from larry flynt ' s outlandish stunts at his courtroom appearances - some of his chosen apparel is hilarious - and for the most part these elements of the film work far better than some of the more dramatic points , such as an uninspiring flynt monologue set at a free speech rally in front of an enormous american flag dealing with the subjectivity of obscenity . the film ' s focus is on the flynt ' s many battles over first amendment rights and freedom of speech , but the heart of the people vs . larry flynt is the touching love story between flynt and althea . larry flynt is shown as being occassionally gruff , harsh , and overtly aggressive with his friends and colleagues , but with althea , we see his loving , affectionate side . there ' s a scene where flynt tenderly takes his ill wife on a ride on his wheelchair that is heartbreaking . ultimately , the emotional power that the film hits at its conclusion comes not from his achievements from his battles against censors , but from the strength of flynt and althea ' s love for each other . woody harrelson is entirely engaging in what must be certainly a career - topping performance as the irrepressible larry flynt . harrelson plays flynt with the right mixture of outrageousness and confident stubborness to make him endearing and entirely sympathetic to the audience , and a very compelling protagonist for the film . courtney love plays althea leasure in a startling turn , completely raw and impulsive . it ' s a very solid performance , brash and naturalistic , and love is extremely compelling ; it ' s difficult to take your eyes off her onscreen , and her chemistry with harrelson is dead - on . edward norton , as flynt ' s straight , level - headed lawyer is often upstaged by his flashier co - stars in the people vs . larry flynt , much as his counterpart lawyer alan isaacman was upstaged by flynt during many of the courtroom scenes , but norton shines in his big scene where he addresses the supreme court in the climactic scene of the film . one can sense the frustration that norton ' s character feels when harrelson ' s free - talking flynt sabotages trial after trial on him by openly speaking his mind , and this results in a heightened emotional punch when norton ' s isaacman has the opportunity to sway the supreme court judges . milos forman keeps the film moving - although it runs over two hours , it never drags - and his direction of the film is very effective , eliciting a great deal of empathy for a subject which could be construed by some as extremely sordid and unsympathetic . there ' s also a great visual technique which forman uses to indicate the passing of time in one shot , which is both clever and extremely entertaining . two minor quibbles with the film - it certainly seems like the people vs . larry flynt is in a rush to get to its main theme , with flynt battling against authorities and the system for his freedom of speech . consequently , the first thirty minutes of the film , introducing and setting up the characters , seem unduly rushed ; perhaps it is merely due to the fact that these characters are so interesting , but i felt it would have worked better if this route was taken in a more leisurely fashion . it also felt like there was a distinctive lack of insight into the inner workings of these characters - the film clearly shows what flynt , althea , isaacman , and rev . jerry faldwell did , and on a superficial level some of their motivations , but it never seemed like one could really understand the characters on a deeper level . for example , why larry flynt was compelled by ruth carter stapleton ( president carter ' s sister ) to be born - again is a mystery to me . then again , perhaps it was to him as well . these two points don ' t detract greatly from the film . the people vs . larry flynt is certainly among the very best studio - released films of 1996 , and works both as a ringing political statement about the importance of freedom of speech and the depths to which larry flynt would go to advance the cause of free expression , and as a touching love story .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Xem kết quả review đầu tiên (dòng 0, cột 1)\n"
      ],
      "metadata": {
        "id": "KrVxWR5CtFgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents[0][1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mJn-zv0ftF1q",
        "outputId": "f176d6e1-beab-4f20-c8ef-0a8307611074"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tạo bảng phân phối tần số các từ trong copus, bảng này cần chuyển sang dạng list, ta dùng\n",
        "hàm list()"
      ],
      "metadata": {
        "id": "HDNGv3J9tHbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = nltk.FreqDist(w.lower() for w in reviews.words())\n",
        "word_features = list(all_words)\n"
      ],
      "metadata": {
        "id": "pkUIbt0ltKa5"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sau đó, bước tiếp theo là xác định một hàm để tính toán các đặc trưng, tức là những từ đủ quan\n",
        "trọng để thiết lập ý kiến của một review."
      ],
      "metadata": {
        "id": "BZceGATZtNNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def document_features(document, word_features):\n",
        " document_words = set(document)\n",
        " features = {}\n",
        " for word in word_features:\n",
        "  features['{}'.format(word)] = (word in document_words)\n",
        " return features\n"
      ],
      "metadata": {
        "id": "uZ7C1O3ktO5z"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Khi bạn định nghĩa hàm document_features(), bạn tạo 1 tập các documents\n"
      ],
      "metadata": {
        "id": "u5Z-Mo9-tUMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featuresets = [(document_features(d,word_features), c) for (d,c) in documents]\n",
        "len(featuresets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OBmqR1etUeD",
        "outputId": "3a29aff8-4d10-46af-812d-11b0d8d0de09"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tạo tập train và tập test: 1500 dòng đầu dùng cho tập train và 500 dòng còn lại dùng cho tập test\n",
        "để đánh giá độ chính xác của mô hình."
      ],
      "metadata": {
        "id": "LGgwYP3WtYnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, test_set = featuresets[1500:], featuresets[:500]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n"
      ],
      "metadata": {
        "id": "IIZq5XHdtZEq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dùng thuật toán Naïve Bayes để phân loại, dùng thư viện NLTK. Sau đó tính toán độ chính xác\n",
        "của thuật toán"
      ],
      "metadata": {
        "id": "lCtniKmmtcHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, est_set = featuresets[1500:], featuresets[:500]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAYPXIeftcvP",
        "outputId": "48504620-9c56-477a-947e-e05ad0c59f2e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chúng ta đã hoàn tất việc phân tích, dưới đây các từ với trọng số lớn nhất của các review được\n",
        "đánh giá là positive và negative\n"
      ],
      "metadata": {
        "id": "ieC47pjgvg3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.show_most_informative_features(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiNgLqkBvhNG",
        "outputId": "6f24ac05-f7b5-4145-c7a6-3d63007b53bb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "                    dull = True              neg : pos    =     14.7 : 1.0\n",
            "             wonderfully = True              pos : neg    =     12.7 : 1.0\n",
            "               painfully = True              neg : pos    =     11.3 : 1.0\n",
            "                  finest = True              pos : neg    =      9.4 : 1.0\n",
            "                    lets = True              pos : neg    =      9.4 : 1.0\n",
            "                     era = True              pos : neg    =      8.8 : 1.0\n",
            "           extraordinary = True              pos : neg    =      8.8 : 1.0\n",
            "                   saved = True              neg : pos    =      8.5 : 1.0\n",
            "                  sports = True              neg : pos    =      8.5 : 1.0\n",
            "                  turkey = True              neg : pos    =      8.5 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Bài tập áp dụng**"
      ],
      "metadata": {
        "id": "kuEfzyoLvy5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.1 Viết chương trình Python với thư viện NLTK để liệt kê các tên của copus.**"
      ],
      "metadata": {
        "id": "qmco6gX-v2kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "\n",
        "from nltk.corpus import gutenberg\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9rtFjvLpv11w",
        "outputId": "945833e8-3112-494b-94a2-bc0735cf6d8b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tải dữ liệu cần thiết\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('gutenberg')\n",
        "\n",
        "def extract_names(text):\n",
        "    tokens = word_tokenize(text)  # Tách từ\n",
        "    tagged_words = pos_tag(tokens)  # Gán nhãn từ loại\n",
        "    names = {word for word, tag in tagged_words if tag in ['NNP', 'NNPS']}  # Lọc danh từ riêng\n",
        "    return names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG_4zlE8ySeZ",
        "outputId": "508fd91b-60dd-489a-9889-99c7203f7ba2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kiểm tra lại danh sách văn bản trong Gutenberg để đảm bảo có file\n",
        "print(\"Danh sách file trong Gutenberg:\", gutenberg.fileids())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6Kbe-2RyjEP",
        "outputId": "096177ed-2a5f-4194-cb7b-f7f73a9c79a8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Danh sách file trong Gutenberg: ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chọn văn bản (đảm bảo nó tồn tại)\n",
        "text = gutenberg.raw('carroll-alice.txt')\n",
        "names_list = extract_names(text)"
      ],
      "metadata": {
        "id": "On6k79njyk_6"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# liệt kê các tên của copus\n",
        "print(\"Danh sách tên riêng trong corpus:\")\n",
        "print(names_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoC6b-Inymcq",
        "outputId": "f1dde653-4284-4356-f6af-ddca8e1156c3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Danh sách tên riêng trong corpus:\n",
            "{'Ugh', 'VII', 'Too', 'Sir', 'THEN', \"'how\", 'means', 'HIM', 'SHOES', 'WILLIAM', \"'Curiouser\", 'Tarts', 'English', '*', 'NEAR', 'Fish-Footman', 'Christmas', 'MINE', 'COULD', 'IN', 'TO', 'Run', 'FENDER', 'Coming', 'V.', 'WHATEVER', 'RETURNED', 'CAN', 'Father', \"'arrum\", 'HE', 'Rabbit', \"'There\", 'VERY', 'VI', 'W', 'ME', 'Ann', 'WASHING', 'HEARTHRUG', 'Stretching', 'MYSELF', 'Pool', 'FATHER', 'IT', 'Mock', 'BE', \"Ma'am\", 'Which', 'Pray', \"'And\", 'Queen', \"'poison\", 'PLENTY', 'Edgar', 'Longitude', 'Said', 'ALL', \"'Come\", 'C', 'FUL', 'INSIDE', 'HAVE', 'Twinkle', 'HERE', 'Tortoise', 'Wonderland', 'Him', 'RIGHT', 'London', 'Alice', 'Fainting', 'Do', 'II', 'KING', 'Miss', 'Soo', 'Tears', 'NO', 'King', 'Sends', 'Arithmetic', 'March', 'Derision', 'WITH', 'Uglification', 'Visit', 'Lobster', 'Carroll', 'Adventures', 'Pigeon', 'Pennyworth', 'MILE', 'VOICE', 'Serpent', 'Zealand', 'Lory', \"'it\", 'AT', 'Off', 'HOW', 'Canary', 'Has', 'Cat', 'OF', 'HIGH', 'Trims', 'Grief', 'France', 'Please', 'Drawling', 'Ada', 'Nile', 'Atheling', 'XI', 'WE', 'Good-bye', 'WAISTCOAT-POCKET', 'LITTLE', 'Grammar', \"'you\", 'Story', 'Lacie', 'Hearts', 'D', 'BEE', 'Imagine', 'Footman', 'Latitude', 'Caucus-race', 'Eaglet', 'Silence', 'WHAT', 'Shark', 'Hatter', 'Soup', 'Classics', 'Dormouse', 'GAVE', 'Five', 'Mystery', 'Beau', 'Gryphon', 'Distraction', 'THAT', 'FROM', 'VIII', 'BOOTS', 'White', 'LEAVE', 'IV', 'ITS', 'Lizard', 'Beautiful', \"'The\", 'NOT', 'Cat.', 'MUST', 'Will', 'Elsie', 'WOULD', 'May', 'New', 'Cheshire', 'YOUR', 'Writhing', 'England', 'Brandy', 'Hare', 'Ma', 'AND', 'Number', 'Pepper', 'Time', 'SOME', 'Mercia', \"'You\", 'Antipathies', 'Keep', 'Quadrille', 'Prizes', 'BEST', 'MARMALADE', 'Suppress', 'Dinah', 'Puss', 'Table', 'French', 'Crab', 'Mabel', '_I_', 'Morcar', 'OLD', 'Stigand', 'Coils', 'Paris', 'THEIR', 'FIT', 'Seaography', 'Advice', 'HIS', 'SOUP', 'Normans', 'Poor', 'RABBIT', 'Multiplication', 'Geography', \"'It\", 'Forty-two', 'Latin', 'PERSONS', 'Majesty', 'TRUE', 'Bill', ']', 'Duck', 'ARE', 'WATCH', 'Frog-Footman', 'Drawling-master', 'Dinn', 'Between', 'O', 'How', 'Dodo', 'Half-past', 'Rome', 'Ah', 'SLUGGARD', 'Evidence', 'SWIM', 'M', 'Australia', 'Never', 'LOVE', 'MORE', 'HEARTS', 'William', 'Pat', 'Was', \"'and\", 'Owl', 'DOTH', 'Laughing', 'Be', 'XII', 'Tillie', 'SOMEBODY', 'YOU.', 'Lewis', 'Tis', 'So', 'BUSY', 'ONE', 'A', 'Down', 'ESQ', 'COURT', 'NEVER', \"'Turn\", 'Panther', 'THEY', 'TWO', 'WAS', 'Quick', 'THE', 'HER', \"'they\", 'THAN', 'SAID', 'Gryphon.', 'Shakespeare', 'PRECIOUS', 'Game', 'QUEEN', 'Caterpillar', 'KNOW', 'PLEASE', 'Jack-in-the-box', 'FOOT', 'Nay', 'Come', 'THERE', \"'moral\", 'Knave', 'CHAPTER', 'III', 'Turtle', 'Heads', 'Mary', 'OURS', 'Conqueror', \"'This\", 'X', 'Canterbury', 'One', 'Mouse', 'THESE', 'HATED', 'SHE', 'Sounds', 'Soon', 'CHORUS', 'THIS', 'Queens', 'Turn', 'Ambition', 'Pig', 'ALICE', 'IX', 'IF', 'Take', 'Edwin', 'OUTSIDE', 'Seven', 'Northumbria', 'YOU', 'OUT', 'First', 'Kings', 'Magpie', 'Duchess'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.2 Viết chương trình Python với thư viện NLTK để liệt kê danh sách các stopword bằng các ngôn ngữ khác nhau**"
      ],
      "metadata": {
        "id": "jOHk6ifkzAEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "languages = stopwords.fileids()\n",
        "for lang in languages:\n",
        "    print(f\"Stopwords ({lang}): {stopwords.words(lang)[:10]} ...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUgaiBI_zJTg",
        "outputId": "e918aef0-7be1-4950-eef8-3c6e5a481914"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopwords (albanian): ['tyre', 'rreth', 'le', 'atyre', 'këta', 'megjithëse', 'kemi', 'per', 'ndonëse', 'dytë'] ...\n",
            "Stopwords (arabic): ['إذ', 'إذا', 'إذما', 'إذن', 'أف', 'أقل', 'أكثر', 'ألا', 'إلا', 'التي'] ...\n",
            "Stopwords (azerbaijani): ['a', 'ad', 'altı', 'altmış', 'amma', 'arasında', 'artıq', 'ay', 'az', 'bax'] ...\n",
            "Stopwords (basque): ['ahala', 'aitzitik', 'al', 'ala ', 'alabadere', 'alabaina', 'alabaina', 'aldiz ', 'alta', 'amaitu'] ...\n",
            "Stopwords (belarusian): ['на', 'не', 'што', 'па', 'да', 'за', 'як', 'для', 'гэта', 'ад'] ...\n",
            "Stopwords (bengali): ['অতএব', 'অথচ', 'অথবা', 'অনুযায়ী', 'অনেক', 'অনেকে', 'অনেকেই', 'অন্তত', 'অন্য', 'অবধি'] ...\n",
            "Stopwords (catalan): ['a', 'abans', 'ací', 'ah', 'així', 'això', 'al', 'aleshores', 'algun', 'alguna'] ...\n",
            "Stopwords (chinese): ['一', '一下', '一些', '一切', '一则', '一天', '一定', '一方面', '一旦', '一时'] ...\n",
            "Stopwords (danish): ['og', 'i', 'jeg', 'det', 'at', 'en', 'den', 'til', 'er', 'som'] ...\n",
            "Stopwords (dutch): ['de', 'en', 'van', 'ik', 'te', 'dat', 'die', 'in', 'een', 'hij'] ...\n",
            "Stopwords (english): ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an'] ...\n",
            "Stopwords (finnish): ['olla', 'olen', 'olet', 'on', 'olemme', 'olette', 'ovat', 'ole', 'oli', 'olisi'] ...\n",
            "Stopwords (french): ['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle'] ...\n",
            "Stopwords (german): ['aber', 'alle', 'allem', 'allen', 'aller', 'alles', 'als', 'also', 'am', 'an'] ...\n",
            "Stopwords (greek): ['αλλα', 'αν', 'αντι', 'απο', 'αυτα', 'αυτεσ', 'αυτη', 'αυτο', 'αυτοι', 'αυτοσ'] ...\n",
            "Stopwords (hebrew): ['אני', 'את', 'אתה', 'אנחנו', 'אתן', 'אתם', 'הם', 'הן', 'היא', 'הוא'] ...\n",
            "Stopwords (hinglish): ['a', 'aadi', 'aaj', 'aap', 'aapne', 'aata', 'aati', 'aaya', 'aaye', 'ab'] ...\n",
            "Stopwords (hungarian): ['a', 'ahogy', 'ahol', 'aki', 'akik', 'akkor', 'alatt', 'által', 'általában', 'amely'] ...\n",
            "Stopwords (indonesian): ['ada', 'adalah', 'adanya', 'adapun', 'agak', 'agaknya', 'agar', 'akan', 'akankah', 'akhir'] ...\n",
            "Stopwords (italian): ['ad', 'al', 'allo', 'ai', 'agli', 'all', 'agl', 'alla', 'alle', 'con'] ...\n",
            "Stopwords (kazakh): ['ах', 'ох', 'эх', 'ай', 'эй', 'ой', 'тағы', 'тағыда', 'әрине', 'жоқ'] ...\n",
            "Stopwords (nepali): ['छ', 'र', 'पनि', 'छन्', 'लागि', 'भएको', 'गरेको', 'भने', 'गर्न', 'गर्ने'] ...\n",
            "Stopwords (norwegian): ['og', 'i', 'jeg', 'det', 'at', 'en', 'et', 'den', 'til', 'er'] ...\n",
            "Stopwords (portuguese): ['a', 'à', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as'] ...\n",
            "Stopwords (romanian): ['a', 'abia', 'acea', 'aceasta', 'această', 'aceea', 'aceeasi', 'acei', 'aceia', 'acel'] ...\n",
            "Stopwords (russian): ['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со'] ...\n",
            "Stopwords (slovene): ['ali', 'ampak', 'bodisi', 'in', 'kajti', 'marveč', 'namreč', 'ne', 'niti', 'oziroma'] ...\n",
            "Stopwords (spanish): ['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se'] ...\n",
            "Stopwords (swedish): ['och', 'det', 'att', 'i', 'en', 'jag', 'hon', 'som', 'han', 'på'] ...\n",
            "Stopwords (tajik): ['аз', 'дар', 'ба', 'бо', 'барои', 'бе', 'то', 'ҷуз', 'пеши', 'назди'] ...\n",
            "Stopwords (turkish): ['acaba', 'ama', 'aslında', 'az', 'bazı', 'belki', 'biri', 'birkaç', 'birşey', 'biz'] ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.3. Viết chương trình Python với thư viện NLTK để kiểm tra danh sách các stopword bằng các ngôn ngữ khác nhau.**"
      ],
      "metadata": {
        "id": "83vbrZO9zRpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_stopword(word, lang):\n",
        "    return word.lower() in stopwords.words(lang)\n",
        "\n",
        "print(\"the in english: \",check_stopword(\"the\", \"english\"))  # True\n",
        "print(\"le in french: \",check_stopword(\"le\", \"french\"))    # True\n",
        "print(\"tyre in english: \",check_stopword(\"tyre\", \"english\"))   # False\n",
        "print(\"det in danish: \",check_stopword(\"det\", \"danish\"))    # True\n",
        "print(\"amma in english: \",check_stopword(\"amma\", \"english\"))   # False\n",
        "print(\"অতএব in nepali: \", check_stopword(\"অতএব\", \"nepali\"))   # False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB9ImmOxzV9F",
        "outputId": "9bebe5c7-43ee-4270-c38d-cbd7b7a53213"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the in english:  True\n",
            "le in french:  True\n",
            "tyre in english:  False\n",
            "det in danish:  True\n",
            "amma in english:  False\n",
            "অতএব in nepali:  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.4 Viết chương trình Python với thư viện NLTK để loại bỏ các stopword từ một văn bản đã cho**"
      ],
      "metadata": {
        "id": "Y5VZjCpQ1RFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text, lang=\"english\"):\n",
        "    words = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words(lang))\n",
        "    return \" \".join([word for word in words if word.lower() not in stop_words])\n",
        "\n",
        "sample_text = \"This is an example sentence demonstrating stopword removal.\"\n",
        "print(remove_stopwords(sample_text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsCaV2vZ1TNY",
        "outputId": "c5cf3d6b-bca3-499e-eb13-533e3db3aa29"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example sentence demonstrating stopword removal .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.5 Viết chương trình Python với thư viện NLTK bỏ qua các stopword từ danh sách các stopword.**"
      ],
      "metadata": {
        "id": "H-LLkPU41qAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_stopwords = set(stopwords.words(\"english\")) - {\"not\", \"no\"}\n",
        "print(custom_stopwords)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcnQZlJk1v4x",
        "outputId": "21a1e79e-7adf-43c2-c5a5-0ac49e791dec"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"she's\", 'once', \"you're\", 'a', \"needn't\", 'against', 'with', 'who', 'as', 'shouldn', 'wouldn', 'during', 'into', 'its', 'just', \"she'll\", 'do', \"i'll\", 'off', 'been', 'hers', 'about', 'other', 'are', 'any', 'needn', 'isn', 'for', 'out', 'having', 'on', 'so', 'ours', 'o', 'up', 're', 'some', \"it'll\", \"we'd\", 't', 'this', 'herself', 'then', 'of', 'such', \"don't\", 'those', 'where', 'were', \"it's\", \"we've\", \"wouldn't\", 'in', 'same', 'the', 'now', 'aren', \"shan't\", \"doesn't\", \"they'd\", 'being', 'hadn', 'whom', 'our', 'yours', 'had', \"they'll\", \"mightn't\", 'did', 'over', 'when', 'further', \"i'm\", \"hasn't\", 'to', 'both', 'don', 'by', \"we'll\", 'while', 'more', 've', 'at', 'there', 'ma', 'until', \"you'll\", 'her', 'is', 'all', 'didn', 'them', 'can', 'doing', 'after', 'if', \"weren't\", \"didn't\", 'theirs', 'him', 'i', \"he'd\", 'few', 'which', 'down', 'or', 'am', 'should', 'but', 'each', 'm', \"you've\", 'wasn', 'most', 'himself', \"i've\", 'we', 'how', 'yourself', 'ain', 'be', \"she'd\", 'they', 'own', 'doesn', \"shouldn't\", 'what', 'yourselves', 'nor', 'you', \"he'll\", 'y', 'will', \"i'd\", 'from', 'weren', 'again', 'through', 'your', 'mustn', \"should've\", 'these', 'won', 'below', 'under', 'has', 'myself', \"he's\", 'only', 'their', \"they've\", 'very', 's', 'have', \"couldn't\", 'd', \"that'll\", 'hasn', 'it', 'me', \"you'd\", 'mightn', 'does', \"they're\", \"we're\", \"hadn't\", 'than', 'itself', 'and', 'he', \"isn't\", 'between', \"won't\", 'shan', 'was', 'll', 'haven', 'an', 'because', 'too', 'my', \"wasn't\", 'above', \"aren't\", 'his', 'themselves', 'couldn', \"it'd\", 'why', 'ourselves', 'here', 'she', \"haven't\", 'that', \"mustn't\", 'before'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.6 Viết một chương trình Python với thư viện NLTK để tìm định nghĩa và ví dụ của một từ đã\n",
        "cho bằng WordNet từ Wikipedia**"
      ],
      "metadata": {
        "id": "9xXpeIRY1xlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "def get_word_info(word):\n",
        "    synsets = wordnet.synsets(word)\n",
        "    for syn in synsets:\n",
        "        print(f\"Định nghĩa: {syn.definition()}\")\n",
        "        print(f\"Ví dụ: {syn.examples()}\")\n",
        "\n",
        "get_word_info(\"computer\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4b9Hl8j11la",
        "outputId": "59a707ee-b236-4f78-a778-018c162a367e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Định nghĩa: a machine for performing calculations automatically\n",
            "Ví dụ: []\n",
            "Định nghĩa: an expert at calculation (or at operating calculating machines)\n",
            "Ví dụ: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.7. Viết chương trình Python với thư viện NLTK để tìm tập hợp các từ đồng nghĩa và trái nghĩa\n",
        "của một từ nào đó.**"
      ],
      "metadata": {
        "id": "l6ABa30z1-Eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def synonyms_antonyms(word):\n",
        "    synonyms, antonyms = set(), set()\n",
        "\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.add(lemma.name())\n",
        "            if lemma.antonyms():\n",
        "                antonyms.add(lemma.antonyms()[0].name())\n",
        "\n",
        "    print(f\"Từ đồng nghĩa của happy: {synonyms}\")\n",
        "    print(f\"Từ trái nghĩa của happy: {antonyms}\")\n",
        "\n",
        "synonyms_antonyms(\"happy\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXmCBlNl1_qu",
        "outputId": "7b6e9434-d64f-42f8-cdfd-bdb295245a64"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Từ đồng nghĩa của happy: {'glad', 'well-chosen', 'felicitous', 'happy'}\n",
            "Từ trái nghĩa của happy: {'unhappy'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.8 Viết chương trình Python với thư viện NLTK để có cái nhìn tổng quan về bộ tag, chi tiết của\n",
        "một tag cụ thể trong bộ tag và chi tiết về một số bộ tag liên quan, sử dụng biểu thức chính\n",
        "quy**"
      ],
      "metadata": {
        "id": "ZtkYrXpY2L0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('tagsets')\n",
        "\n",
        "nltk.help.upenn_tagset('NN')  # Xem chi tiết tag danh từ\n",
        "nltk.help.upenn_tagset()       # Xem toàn bộ tag\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbuK4oqn2QNS",
        "outputId": "6d333eff-f202-4dec-996d-faefd3528c47"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n",
            "$: dollar\n",
            "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
            "'': closing quotation mark\n",
            "    ' ''\n",
            "(: opening parenthesis\n",
            "    ( [ {\n",
            "): closing parenthesis\n",
            "    ) ] }\n",
            ",: comma\n",
            "    ,\n",
            "--: dash\n",
            "    --\n",
            ".: sentence terminator\n",
            "    . ! ?\n",
            ":: colon or ellipsis\n",
            "    : ; ...\n",
            "CC: conjunction, coordinating\n",
            "    & 'n and both but either et for less minus neither nor or plus so\n",
            "    therefore times v. versus vs. whether yet\n",
            "CD: numeral, cardinal\n",
            "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
            "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
            "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
            "DT: determiner\n",
            "    all an another any both del each either every half la many much nary\n",
            "    neither no some such that the them these this those\n",
            "EX: existential there\n",
            "    there\n",
            "FW: foreign word\n",
            "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
            "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
            "    terram fiche oui corporis ...\n",
            "IN: preposition or conjunction, subordinating\n",
            "    astride among uppon whether out inside pro despite on by throughout\n",
            "    below within for towards near behind atop around if like until below\n",
            "    next into if beside ...\n",
            "JJ: adjective or numeral, ordinal\n",
            "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
            "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
            "    multilingual multi-disciplinary ...\n",
            "JJR: adjective, comparative\n",
            "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
            "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
            "    cozier creamier crunchier cuter ...\n",
            "JJS: adjective, superlative\n",
            "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
            "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
            "    dearest deepest densest dinkiest ...\n",
            "LS: list item marker\n",
            "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
            "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
            "    two\n",
            "MD: modal auxiliary\n",
            "    can cannot could couldn't dare may might must need ought shall should\n",
            "    shouldn't will would\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n",
            "NNP: noun, proper, singular\n",
            "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
            "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
            "    Shannon A.K.C. Meltex Liverpool ...\n",
            "NNPS: noun, proper, plural\n",
            "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
            "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
            "    Apache Apaches Apocrypha ...\n",
            "NNS: noun, common, plural\n",
            "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
            "    divestitures storehouses designs clubs fragrances averages\n",
            "    subjectivists apprehensions muses factory-jobs ...\n",
            "PDT: pre-determiner\n",
            "    all both half many quite such sure this\n",
            "POS: genitive marker\n",
            "    ' 's\n",
            "PRP: pronoun, personal\n",
            "    hers herself him himself hisself it itself me myself one oneself ours\n",
            "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
            "PRP$: pronoun, possessive\n",
            "    her his mine my our ours their thy your\n",
            "RB: adverb\n",
            "    occasionally unabatingly maddeningly adventurously professedly\n",
            "    stirringly prominently technologically magisterially predominately\n",
            "    swiftly fiscally pitilessly ...\n",
            "RBR: adverb, comparative\n",
            "    further gloomier grander graver greater grimmer harder harsher\n",
            "    healthier heavier higher however larger later leaner lengthier less-\n",
            "    perfectly lesser lonelier longer louder lower more ...\n",
            "RBS: adverb, superlative\n",
            "    best biggest bluntest earliest farthest first furthest hardest\n",
            "    heartiest highest largest least less most nearest second tightest worst\n",
            "RP: particle\n",
            "    aboard about across along apart around aside at away back before behind\n",
            "    by crop down ever fast for forth from go high i.e. in into just later\n",
            "    low more off on open out over per pie raising start teeth that through\n",
            "    under unto up up-pp upon whole with you\n",
            "SYM: symbol\n",
            "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
            "TO: \"to\" as preposition or infinitive marker\n",
            "    to\n",
            "UH: interjection\n",
            "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
            "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
            "    man baby diddle hush sonuvabitch ...\n",
            "VB: verb, base form\n",
            "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
            "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
            "    boost brace break bring broil brush build ...\n",
            "VBD: verb, past tense\n",
            "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
            "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
            "    speculated wore appreciated contemplated ...\n",
            "VBG: verb, present participle or gerund\n",
            "    telegraphing stirring focusing angering judging stalling lactating\n",
            "    hankerin' alleging veering capping approaching traveling besieging\n",
            "    encrypting interrupting erasing wincing ...\n",
            "VBN: verb, past participle\n",
            "    multihulled dilapidated aerosolized chaired languished panelized used\n",
            "    experimented flourished imitated reunifed factored condensed sheared\n",
            "    unsettled primed dubbed desired ...\n",
            "VBP: verb, present tense, not 3rd person singular\n",
            "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
            "    appear tend stray glisten obtain comprise detest tease attract\n",
            "    emphasize mold postpone sever return wag ...\n",
            "VBZ: verb, present tense, 3rd person singular\n",
            "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
            "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
            "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
            "WDT: WH-determiner\n",
            "    that what whatever which whichever\n",
            "WP: WH-pronoun\n",
            "    that what whatever whatsoever which who whom whosoever\n",
            "WP$: WH-pronoun, possessive\n",
            "    whose\n",
            "WRB: Wh-adverb\n",
            "    how however whence whenever where whereby whereever wherein whereof why\n",
            "``: opening quotation mark\n",
            "    ` ``\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.9 Viết chương trình Python với thư viện NLTK để so sánh sự giống nhau của hai danh từ đã cho.**"
      ],
      "metadata": {
        "id": "7iHns7g-2Vzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word1 = wordnet.synsets('cat', pos=wordnet.NOUN)[0]\n",
        "word2 = wordnet.synsets('dog', pos=wordnet.NOUN)[0]\n",
        "\n",
        "print(\"Mức độ giống nhau giữa cat và dog:\", word1.wup_similarity(word2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaBOo1Ks2diU",
        "outputId": "d4201852-86ef-4df5-85fc-534c63312240"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mức độ giống nhau giữa cat và dog: 0.8571428571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.10 Viết chương trình Python với thư viện NLTK để so sánh sự giống nhau của hai động từ đã\n",
        "cho**"
      ],
      "metadata": {
        "id": "t2WC6Q-P2iJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word1 = wordnet.synsets('run', pos=wordnet.VERB)[0]\n",
        "word2 = wordnet.synsets('walk', pos=wordnet.VERB)[0]\n",
        "\n",
        "print(\"Mức độ giống nhau giữa run và walk:\", word1.wup_similarity(word2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctMXGLYo2mwP",
        "outputId": "f73c87e4-7bfa-4ee0-a66e-c23827566030"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mức độ giống nhau giữa run và walk: 0.2857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.11 Viết chương trình Python với thư viện NLTK để tìm số lượng tên nam và nữ trong các tên\n",
        "kho ngữ liệu. In tên 10 nam và nữ đầu tiên. Lưu ý: Kho văn bản tên chứa tổng cộng khoảng\n",
        "2943 nam (male.txt) và 5001 nữ (Female.txt) tên. Kho được biên soạn bởi Kantrowitz, Ross**"
      ],
      "metadata": {
        "id": "e1twaoJk4Cy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import names\n",
        "\n",
        "nltk.download('names')\n",
        "\n",
        "male_names = names.words('male.txt')\n",
        "female_names = names.words('female.txt')\n",
        "\n",
        "print(f\"Số lượng tên nam: {len(male_names)}\")\n",
        "print(f\"Số lượng tên nữ: {len(female_names)}\")\n",
        "\n",
        "print(\"10 tên nam đầu tiên:\", male_names[:10])\n",
        "print(\"10 tên nữ đầu tiên:\", female_names[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cchtrJmI4GFy",
        "outputId": "b41d7142-23b8-4432-f442-bb310fb372ac"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số lượng tên nam: 2943\n",
            "Số lượng tên nữ: 5001\n",
            "10 tên nam đầu tiên: ['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot', 'Abbott', 'Abby', 'Abdel', 'Abdul', 'Abdulkarim']\n",
            "10 tên nữ đầu tiên: ['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi', 'Abbie', 'Abby', 'Abigael', 'Abigail', 'Abigale']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.12 Viết chương trình Python với thư viện NLTK để in 15 kết hợp ngẫu nhiên đầu tiên được gắn\n",
        "nhãn nam và được gắn nhãn tên nữ từ kho tên.**"
      ],
      "metadata": {
        "id": "UhAtj8o14I4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random_male = random.sample(male_names, 15)\n",
        "random_female = random.sample(female_names, 15)\n",
        "\n",
        "print(\"Tên nam:\", random_male)\n",
        "print(\"Tên nữ:\", random_female)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_SXQg974LC-",
        "outputId": "54163bae-3c4b-4e4e-e577-ca2c6b28a6fc"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tên nam: ['Herculie', 'Ingmar', 'Zechariah', 'Walker', 'Herbie', 'Cy', 'Edouard', 'Jack', 'Emmett', 'Simmonds', 'Baldwin', 'Donn', 'Cain', 'Paddie', 'Jamey']\n",
            "Tên nữ: ['Clotilda', 'Annabela', 'Alberta', 'Ursola', 'Timmie', 'Roxane', 'Miran', 'Vicky', 'Yvette', 'Bari', 'Dew', 'Wini', 'Gae', 'Carrol', 'Yolanda']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.13 Viết chương trình Python với thư viện NLTK để trích xuất ký tự cuối cùng của tất cả các tên\n",
        "được gắn nhãn và tạo mảng mới với chữ cái cuối cùng của mỗi tên và nhãn được liên kết.**"
      ],
      "metadata": {
        "id": "T7O9AUPy4Pxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_last_letter():\n",
        "    labeled_names = [(name[-1], 'male') for name in male_names] + [(name[-1], 'female') for name in female_names]\n",
        "    return labeled_names\n",
        "\n",
        "print(\"Mẫu ký tự cuối cùng và nhãn:\")\n",
        "print(extract_last_letter()[:15])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxl0Quy64Xwy",
        "outputId": "0367cd4e-5832-4d6d-f8ff-b696cbb0cb31"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mẫu ký tự cuối cùng và nhãn:\n",
            "[('r', 'male'), ('n', 'male'), ('y', 'male'), ('e', 'male'), ('t', 'male'), ('t', 'male'), ('y', 'male'), ('l', 'male'), ('l', 'male'), ('m', 'male'), ('h', 'male'), ('e', 'male'), ('l', 'male'), ('d', 'male'), ('r', 'male')]\n"
          ]
        }
      ]
    }
  ]
}